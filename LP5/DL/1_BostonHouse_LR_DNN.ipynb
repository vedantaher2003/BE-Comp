{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0c8DdGw1mrB0"
      },
      "source": [
        "PS: Linear regression by using Deep Neural Network: Implement Boston housing price prediction problem by Linear regression using Deep Neural Network. Use Boston House price prediction dataset."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "NwcENUehsvYm",
        "outputId": "6a2450ff-d304-4c8d-8b13-de3048397ed7"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>crim</th>\n",
              "      <th>zn</th>\n",
              "      <th>indus</th>\n",
              "      <th>chas</th>\n",
              "      <th>nox</th>\n",
              "      <th>rm</th>\n",
              "      <th>age</th>\n",
              "      <th>dis</th>\n",
              "      <th>rad</th>\n",
              "      <th>tax</th>\n",
              "      <th>ptratio</th>\n",
              "      <th>b</th>\n",
              "      <th>lstat</th>\n",
              "      <th>MEDV</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0.00632</td>\n",
              "      <td>18.0</td>\n",
              "      <td>2.31</td>\n",
              "      <td>0</td>\n",
              "      <td>0.538</td>\n",
              "      <td>6.575</td>\n",
              "      <td>65.2</td>\n",
              "      <td>4.0900</td>\n",
              "      <td>1</td>\n",
              "      <td>296</td>\n",
              "      <td>15.3</td>\n",
              "      <td>396.90</td>\n",
              "      <td>4.98</td>\n",
              "      <td>24.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0.02731</td>\n",
              "      <td>0.0</td>\n",
              "      <td>7.07</td>\n",
              "      <td>0</td>\n",
              "      <td>0.469</td>\n",
              "      <td>6.421</td>\n",
              "      <td>78.9</td>\n",
              "      <td>4.9671</td>\n",
              "      <td>2</td>\n",
              "      <td>242</td>\n",
              "      <td>17.8</td>\n",
              "      <td>396.90</td>\n",
              "      <td>9.14</td>\n",
              "      <td>21.6</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>0.02729</td>\n",
              "      <td>0.0</td>\n",
              "      <td>7.07</td>\n",
              "      <td>0</td>\n",
              "      <td>0.469</td>\n",
              "      <td>7.185</td>\n",
              "      <td>61.1</td>\n",
              "      <td>4.9671</td>\n",
              "      <td>2</td>\n",
              "      <td>242</td>\n",
              "      <td>17.8</td>\n",
              "      <td>392.83</td>\n",
              "      <td>4.03</td>\n",
              "      <td>34.7</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>0.03237</td>\n",
              "      <td>0.0</td>\n",
              "      <td>2.18</td>\n",
              "      <td>0</td>\n",
              "      <td>0.458</td>\n",
              "      <td>6.998</td>\n",
              "      <td>45.8</td>\n",
              "      <td>6.0622</td>\n",
              "      <td>3</td>\n",
              "      <td>222</td>\n",
              "      <td>18.7</td>\n",
              "      <td>394.63</td>\n",
              "      <td>2.94</td>\n",
              "      <td>33.4</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0.06905</td>\n",
              "      <td>0.0</td>\n",
              "      <td>2.18</td>\n",
              "      <td>0</td>\n",
              "      <td>0.458</td>\n",
              "      <td>7.147</td>\n",
              "      <td>54.2</td>\n",
              "      <td>6.0622</td>\n",
              "      <td>3</td>\n",
              "      <td>222</td>\n",
              "      <td>18.7</td>\n",
              "      <td>396.90</td>\n",
              "      <td>5.33</td>\n",
              "      <td>36.2</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "      crim    zn  indus  chas    nox     rm   age     dis  rad  tax  ptratio  \\\n",
              "0  0.00632  18.0   2.31     0  0.538  6.575  65.2  4.0900    1  296     15.3   \n",
              "1  0.02731   0.0   7.07     0  0.469  6.421  78.9  4.9671    2  242     17.8   \n",
              "2  0.02729   0.0   7.07     0  0.469  7.185  61.1  4.9671    2  242     17.8   \n",
              "3  0.03237   0.0   2.18     0  0.458  6.998  45.8  6.0622    3  222     18.7   \n",
              "4  0.06905   0.0   2.18     0  0.458  7.147  54.2  6.0622    3  222     18.7   \n",
              "\n",
              "        b  lstat  MEDV  \n",
              "0  396.90   4.98  24.0  \n",
              "1  396.90   9.14  21.6  \n",
              "2  392.83   4.03  34.7  \n",
              "3  394.63   2.94  33.4  \n",
              "4  396.90   5.33  36.2  "
            ]
          },
          "execution_count": 1,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "import pandas as pd\n",
        "\n",
        "df = pd.read_csv(\"https://raw.githubusercontent.com/Srushti-S/BE_Assignments/main/LP5/DL/boston_housing.csv\")\n",
        "\n",
        "df.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "RvPeT86pzePQ"
      },
      "outputs": [],
      "source": [
        "# X = df.drop('MEDV', axis=1)\n",
        "# y = df['MEDV']\n",
        "\n",
        "X = df.loc[:, df.columns != 'MEDV']\n",
        "y = df.loc[:, df.columns == 'MEDV']"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "4FEDjg8rsyi0"
      },
      "outputs": [],
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=45)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "6bUw9e7-Z3bI"
      },
      "outputs": [],
      "source": [
        "# Normalization\n",
        "\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "mms = MinMaxScaler()\n",
        "# mms.fit(X_train)\n",
        "# X_train = mms.transform(X_train)\n",
        "# mms.fit(X_test)\n",
        "# X_test = mms.transform(X_test)\n",
        "\n",
        "X_train = mms.fit_transform(X_train)\n",
        "X_test = mms.fit_transform(X_test)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Collecting tensorflow\n",
            "  Downloading tensorflow-2.19.0-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (4.1 kB)\n",
            "Requirement already satisfied: absl-py>=1.0.0 in /usr/local/python/3.12.1/lib/python3.12/site-packages (from tensorflow) (2.2.2)\n",
            "Collecting astunparse>=1.6.0 (from tensorflow)\n",
            "  Downloading astunparse-1.6.3-py2.py3-none-any.whl.metadata (4.4 kB)\n",
            "Collecting flatbuffers>=24.3.25 (from tensorflow)\n",
            "  Downloading flatbuffers-25.2.10-py2.py3-none-any.whl.metadata (875 bytes)\n",
            "Collecting gast!=0.5.0,!=0.5.1,!=0.5.2,>=0.2.1 (from tensorflow)\n",
            "  Downloading gast-0.6.0-py3-none-any.whl.metadata (1.3 kB)\n",
            "Collecting google-pasta>=0.1.1 (from tensorflow)\n",
            "  Downloading google_pasta-0.2.0-py3-none-any.whl.metadata (814 bytes)\n",
            "Collecting libclang>=13.0.0 (from tensorflow)\n",
            "  Downloading libclang-18.1.1-py2.py3-none-manylinux2010_x86_64.whl.metadata (5.2 kB)\n",
            "Collecting opt-einsum>=2.3.2 (from tensorflow)\n",
            "  Downloading opt_einsum-3.4.0-py3-none-any.whl.metadata (6.3 kB)\n",
            "Requirement already satisfied: packaging in /home/codespace/.local/lib/python3.12/site-packages (from tensorflow) (24.2)\n",
            "Collecting protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<6.0.0dev,>=3.20.3 (from tensorflow)\n",
            "  Downloading protobuf-5.29.4-cp38-abi3-manylinux2014_x86_64.whl.metadata (592 bytes)\n",
            "Requirement already satisfied: requests<3,>=2.21.0 in /home/codespace/.local/lib/python3.12/site-packages (from tensorflow) (2.32.3)\n",
            "Requirement already satisfied: setuptools in /home/codespace/.local/lib/python3.12/site-packages (from tensorflow) (76.0.0)\n",
            "Requirement already satisfied: six>=1.12.0 in /home/codespace/.local/lib/python3.12/site-packages (from tensorflow) (1.17.0)\n",
            "Collecting termcolor>=1.1.0 (from tensorflow)\n",
            "  Downloading termcolor-3.0.1-py3-none-any.whl.metadata (6.1 kB)\n",
            "Requirement already satisfied: typing-extensions>=3.6.6 in /home/codespace/.local/lib/python3.12/site-packages (from tensorflow) (4.12.2)\n",
            "Collecting wrapt>=1.11.0 (from tensorflow)\n",
            "  Downloading wrapt-1.17.2-cp312-cp312-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (6.4 kB)\n",
            "Collecting grpcio<2.0,>=1.24.3 (from tensorflow)\n",
            "  Downloading grpcio-1.71.0-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (3.8 kB)\n",
            "Collecting tensorboard~=2.19.0 (from tensorflow)\n",
            "  Downloading tensorboard-2.19.0-py3-none-any.whl.metadata (1.8 kB)\n",
            "Requirement already satisfied: keras>=3.5.0 in /usr/local/python/3.12.1/lib/python3.12/site-packages (from tensorflow) (3.9.2)\n",
            "Collecting numpy<2.2.0,>=1.26.0 (from tensorflow)\n",
            "  Downloading numpy-2.1.3-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (62 kB)\n",
            "Requirement already satisfied: h5py>=3.11.0 in /usr/local/python/3.12.1/lib/python3.12/site-packages (from tensorflow) (3.13.0)\n",
            "Requirement already satisfied: ml-dtypes<1.0.0,>=0.5.1 in /usr/local/python/3.12.1/lib/python3.12/site-packages (from tensorflow) (0.5.1)\n",
            "Collecting wheel<1.0,>=0.23.0 (from astunparse>=1.6.0->tensorflow)\n",
            "  Downloading wheel-0.45.1-py3-none-any.whl.metadata (2.3 kB)\n",
            "Requirement already satisfied: rich in /usr/local/python/3.12.1/lib/python3.12/site-packages (from keras>=3.5.0->tensorflow) (14.0.0)\n",
            "Requirement already satisfied: namex in /usr/local/python/3.12.1/lib/python3.12/site-packages (from keras>=3.5.0->tensorflow) (0.0.8)\n",
            "Requirement already satisfied: optree in /usr/local/python/3.12.1/lib/python3.12/site-packages (from keras>=3.5.0->tensorflow) (0.15.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /home/codespace/.local/lib/python3.12/site-packages (from requests<3,>=2.21.0->tensorflow) (3.4.1)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /home/codespace/.local/lib/python3.12/site-packages (from requests<3,>=2.21.0->tensorflow) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /home/codespace/.local/lib/python3.12/site-packages (from requests<3,>=2.21.0->tensorflow) (2.3.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /home/codespace/.local/lib/python3.12/site-packages (from requests<3,>=2.21.0->tensorflow) (2025.1.31)\n",
            "Collecting markdown>=2.6.8 (from tensorboard~=2.19.0->tensorflow)\n",
            "  Downloading markdown-3.8-py3-none-any.whl.metadata (5.1 kB)\n",
            "Collecting tensorboard-data-server<0.8.0,>=0.7.0 (from tensorboard~=2.19.0->tensorflow)\n",
            "  Downloading tensorboard_data_server-0.7.2-py3-none-manylinux_2_31_x86_64.whl.metadata (1.1 kB)\n",
            "Collecting werkzeug>=1.0.1 (from tensorboard~=2.19.0->tensorflow)\n",
            "  Downloading werkzeug-3.1.3-py3-none-any.whl.metadata (3.7 kB)\n",
            "Requirement already satisfied: MarkupSafe>=2.1.1 in /home/codespace/.local/lib/python3.12/site-packages (from werkzeug>=1.0.1->tensorboard~=2.19.0->tensorflow) (3.0.2)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/python/3.12.1/lib/python3.12/site-packages (from rich->keras>=3.5.0->tensorflow) (3.0.0)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /home/codespace/.local/lib/python3.12/site-packages (from rich->keras>=3.5.0->tensorflow) (2.19.1)\n",
            "Requirement already satisfied: mdurl~=0.1 in /usr/local/python/3.12.1/lib/python3.12/site-packages (from markdown-it-py>=2.2.0->rich->keras>=3.5.0->tensorflow) (0.1.2)\n",
            "Downloading tensorflow-2.19.0-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (645.0 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m645.0/645.0 MB\u001b[0m \u001b[31m21.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
            "\u001b[?25hDownloading astunparse-1.6.3-py2.py3-none-any.whl (12 kB)\n",
            "Downloading flatbuffers-25.2.10-py2.py3-none-any.whl (30 kB)\n",
            "Downloading gast-0.6.0-py3-none-any.whl (21 kB)\n",
            "Downloading google_pasta-0.2.0-py3-none-any.whl (57 kB)\n",
            "Downloading grpcio-1.71.0-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (5.9 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m5.9/5.9 MB\u001b[0m \u001b[31m39.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading libclang-18.1.1-py2.py3-none-manylinux2010_x86_64.whl (24.5 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m24.5/24.5 MB\u001b[0m \u001b[31m40.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
            "\u001b[?25hDownloading numpy-2.1.3-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (16.0 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m16.0/16.0 MB\u001b[0m \u001b[31m37.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m\n",
            "\u001b[?25hDownloading opt_einsum-3.4.0-py3-none-any.whl (71 kB)\n",
            "Downloading protobuf-5.29.4-cp38-abi3-manylinux2014_x86_64.whl (319 kB)\n",
            "Downloading tensorboard-2.19.0-py3-none-any.whl (5.5 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m5.5/5.5 MB\u001b[0m \u001b[31m13.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
            "\u001b[?25hDownloading termcolor-3.0.1-py3-none-any.whl (7.2 kB)\n",
            "Downloading wrapt-1.17.2-cp312-cp312-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (89 kB)\n",
            "Downloading markdown-3.8-py3-none-any.whl (106 kB)\n",
            "Downloading tensorboard_data_server-0.7.2-py3-none-manylinux_2_31_x86_64.whl (6.6 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m6.6/6.6 MB\u001b[0m \u001b[31m38.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading werkzeug-3.1.3-py3-none-any.whl (224 kB)\n",
            "Downloading wheel-0.45.1-py3-none-any.whl (72 kB)\n",
            "Installing collected packages: libclang, flatbuffers, wrapt, wheel, werkzeug, termcolor, tensorboard-data-server, protobuf, opt-einsum, numpy, markdown, grpcio, google-pasta, gast, tensorboard, astunparse, tensorflow\n",
            "  Attempting uninstall: numpy\n",
            "    Found existing installation: numpy 2.2.4\n",
            "    Uninstalling numpy-2.2.4:\n",
            "      Successfully uninstalled numpy-2.2.4\n",
            "Successfully installed astunparse-1.6.3 flatbuffers-25.2.10 gast-0.6.0 google-pasta-0.2.0 grpcio-1.71.0 libclang-18.1.1 markdown-3.8 numpy-2.1.3 opt-einsum-3.4.0 protobuf-5.29.4 tensorboard-2.19.0 tensorboard-data-server-0.7.2 tensorflow-2.19.0 termcolor-3.0.1 werkzeug-3.1.3 wheel-0.45.1 wrapt-1.17.2\n"
          ]
        }
      ],
      "source": [
        "# ! pip install keras\n",
        "! pip install tensorflow"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VL8VMy_fs3fl",
        "outputId": "2fd4752c-0043-4cce-9b2d-352b18f45e80"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2025-04-15 06:44:05.867043: I external/local_xla/xla/tsl/cuda/cudart_stub.cc:32] Could not find cuda drivers on your machine, GPU will not be used.\n",
            "2025-04-15 06:44:06.113623: I external/local_xla/xla/tsl/cuda/cudart_stub.cc:32] Could not find cuda drivers on your machine, GPU will not be used.\n",
            "2025-04-15 06:44:06.229857: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:467] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
            "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
            "E0000 00:00:1744699446.505920   39050 cuda_dnn.cc:8579] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
            "E0000 00:00:1744699446.594947   39050 cuda_blas.cc:1407] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
            "W0000 00:00:1744699447.247193   39050 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
            "W0000 00:00:1744699447.247229   39050 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
            "W0000 00:00:1744699447.247232   39050 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
            "W0000 00:00:1744699447.247235   39050 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
            "2025-04-15 06:44:07.281173: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
            "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
          ]
        },
        {
          "ename": "ModuleNotFoundError",
          "evalue": "No module named 'numpy.typing'",
          "output_type": "error",
          "traceback": [
            "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
            "\u001b[31mModuleNotFoundError\u001b[39m                       Traceback (most recent call last)",
            "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[4]\u001b[39m\u001b[32m, line 1\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m1\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mkeras\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mmodels\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m Sequential\n\u001b[32m      2\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mkeras\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mlayers\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m Dense\n\u001b[32m      4\u001b[39m model = Sequential()\n",
            "\u001b[36mFile \u001b[39m\u001b[32m/usr/local/python/3.12.1/lib/python3.12/site-packages/keras/__init__.py:2\u001b[39m\n\u001b[32m      1\u001b[39m \u001b[38;5;66;03m# DO NOT EDIT. Generated by api_gen.sh\u001b[39;00m\n\u001b[32m----> \u001b[39m\u001b[32m2\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mkeras\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mapi\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m DTypePolicy\n\u001b[32m      3\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mkeras\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mapi\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m FloatDTypePolicy\n\u001b[32m      4\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mkeras\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mapi\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m Function\n",
            "\u001b[36mFile \u001b[39m\u001b[32m/usr/local/python/3.12.1/lib/python3.12/site-packages/keras/api/__init__.py:8\u001b[39m\n\u001b[32m      1\u001b[39m \u001b[33;03m\"\"\"DO NOT EDIT.\u001b[39;00m\n\u001b[32m      2\u001b[39m \n\u001b[32m      3\u001b[39m \u001b[33;03mThis file was autogenerated. Do not edit it by hand,\u001b[39;00m\n\u001b[32m      4\u001b[39m \u001b[33;03msince your modifications would be overwritten.\u001b[39;00m\n\u001b[32m      5\u001b[39m \u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m----> \u001b[39m\u001b[32m8\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mkeras\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mapi\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m activations\n\u001b[32m      9\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mkeras\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mapi\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m applications\n\u001b[32m     10\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mkeras\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mapi\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m backend\n",
            "\u001b[36mFile \u001b[39m\u001b[32m/usr/local/python/3.12.1/lib/python3.12/site-packages/keras/api/activations/__init__.py:7\u001b[39m\n\u001b[32m      1\u001b[39m \u001b[33;03m\"\"\"DO NOT EDIT.\u001b[39;00m\n\u001b[32m      2\u001b[39m \n\u001b[32m      3\u001b[39m \u001b[33;03mThis file was autogenerated. Do not edit it by hand,\u001b[39;00m\n\u001b[32m      4\u001b[39m \u001b[33;03msince your modifications would be overwritten.\u001b[39;00m\n\u001b[32m      5\u001b[39m \u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m----> \u001b[39m\u001b[32m7\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mkeras\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01msrc\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mactivations\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m deserialize\n\u001b[32m      8\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mkeras\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01msrc\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mactivations\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m get\n\u001b[32m      9\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mkeras\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01msrc\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mactivations\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m serialize\n",
            "\u001b[36mFile \u001b[39m\u001b[32m/usr/local/python/3.12.1/lib/python3.12/site-packages/keras/src/__init__.py:1\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m1\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mkeras\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01msrc\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m activations\n\u001b[32m      2\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mkeras\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01msrc\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m applications\n\u001b[32m      3\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mkeras\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01msrc\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m backend\n",
            "\u001b[36mFile \u001b[39m\u001b[32m/usr/local/python/3.12.1/lib/python3.12/site-packages/keras/src/activations/__init__.py:3\u001b[39m\n\u001b[32m      1\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mtypes\u001b[39;00m\n\u001b[32m----> \u001b[39m\u001b[32m3\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mkeras\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01msrc\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mactivations\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mactivations\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m celu\n\u001b[32m      4\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mkeras\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01msrc\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mactivations\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mactivations\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m elu\n\u001b[32m      5\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mkeras\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01msrc\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mactivations\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mactivations\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m exponential\n",
            "\u001b[36mFile \u001b[39m\u001b[32m/usr/local/python/3.12.1/lib/python3.12/site-packages/keras/src/activations/activations.py:1\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m1\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mkeras\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01msrc\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m backend\n\u001b[32m      2\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mkeras\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01msrc\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m ops\n\u001b[32m      3\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mkeras\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01msrc\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mapi_export\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m keras_export\n",
            "\u001b[36mFile \u001b[39m\u001b[32m/usr/local/python/3.12.1/lib/python3.12/site-packages/keras/src/backend/__init__.py:10\u001b[39m\n\u001b[32m      7\u001b[39m     \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mtorch\u001b[39;00m\n\u001b[32m      9\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mkeras\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01msrc\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mapi_export\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m keras_export\n\u001b[32m---> \u001b[39m\u001b[32m10\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mkeras\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01msrc\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mbackend\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mcommon\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mdtypes\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m result_type\n\u001b[32m     11\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mkeras\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01msrc\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mbackend\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mcommon\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mkeras_tensor\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m KerasTensor\n\u001b[32m     12\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mkeras\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01msrc\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mbackend\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mcommon\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mkeras_tensor\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m any_symbolic_tensors\n",
            "\u001b[36mFile \u001b[39m\u001b[32m/usr/local/python/3.12.1/lib/python3.12/site-packages/keras/src/backend/common/__init__.py:2\u001b[39m\n\u001b[32m      1\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mkeras\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01msrc\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mbackend\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mcommon\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m backend_utils\n\u001b[32m----> \u001b[39m\u001b[32m2\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mkeras\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01msrc\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mbackend\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mcommon\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mdtypes\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m result_type\n\u001b[32m      3\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mkeras\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01msrc\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mbackend\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mcommon\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mvariables\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m AutocastScope\n\u001b[32m      4\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mkeras\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01msrc\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mbackend\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mcommon\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mvariables\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m Variable \u001b[38;5;28;01mas\u001b[39;00m KerasVariable\n",
            "\u001b[36mFile \u001b[39m\u001b[32m/usr/local/python/3.12.1/lib/python3.12/site-packages/keras/src/backend/common/dtypes.py:5\u001b[39m\n\u001b[32m      3\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mkeras\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01msrc\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mapi_export\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m keras_export\n\u001b[32m      4\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mkeras\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01msrc\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mbackend\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m config\n\u001b[32m----> \u001b[39m\u001b[32m5\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mkeras\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01msrc\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mbackend\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mcommon\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mvariables\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m standardize_dtype\n\u001b[32m      7\u001b[39m BOOL_TYPES = (\u001b[33m\"\u001b[39m\u001b[33mbool\u001b[39m\u001b[33m\"\u001b[39m,)\n\u001b[32m      8\u001b[39m INT_TYPES = (\n\u001b[32m      9\u001b[39m     \u001b[33m\"\u001b[39m\u001b[33muint8\u001b[39m\u001b[33m\"\u001b[39m,\n\u001b[32m     10\u001b[39m     \u001b[33m\"\u001b[39m\u001b[33muint16\u001b[39m\u001b[33m\"\u001b[39m,\n\u001b[32m   (...)\u001b[39m\u001b[32m     16\u001b[39m     \u001b[33m\"\u001b[39m\u001b[33mint64\u001b[39m\u001b[33m\"\u001b[39m,\n\u001b[32m     17\u001b[39m )\n",
            "\u001b[36mFile \u001b[39m\u001b[32m/usr/local/python/3.12.1/lib/python3.12/site-packages/keras/src/backend/common/variables.py:12\u001b[39m\n\u001b[32m     10\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mkeras\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01msrc\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mbackend\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mcommon\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mstateless_scope\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m in_stateless_scope\n\u001b[32m     11\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mkeras\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01msrc\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mutils\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mmodule_utils\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m tensorflow \u001b[38;5;28;01mas\u001b[39;00m tf\n\u001b[32m---> \u001b[39m\u001b[32m12\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mkeras\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01msrc\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mutils\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mnaming\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m auto_name\n\u001b[32m     15\u001b[39m \u001b[38;5;28;01mclass\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mVariable\u001b[39;00m:\n\u001b[32m     16\u001b[39m \u001b[38;5;250m    \u001b[39m\u001b[33;03m\"\"\"Represents a backend-agnostic variable in Keras.\u001b[39;00m\n\u001b[32m     17\u001b[39m \n\u001b[32m     18\u001b[39m \u001b[33;03m    A `Variable` acts as a container for state. It holds a tensor value and can\u001b[39;00m\n\u001b[32m   (...)\u001b[39m\u001b[32m     88\u001b[39m \u001b[33;03m    ```\u001b[39;00m\n\u001b[32m     89\u001b[39m \u001b[33;03m    \"\"\"\u001b[39;00m\n",
            "\u001b[36mFile \u001b[39m\u001b[32m/usr/local/python/3.12.1/lib/python3.12/site-packages/keras/src/utils/__init__.py:1\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m1\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mkeras\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01msrc\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mutils\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01maudio_dataset_utils\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m audio_dataset_from_directory\n\u001b[32m      2\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mkeras\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01msrc\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mutils\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mdataset_utils\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m split_dataset\n\u001b[32m      3\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mkeras\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01msrc\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mutils\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mfile_utils\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m get_file\n",
            "\u001b[36mFile \u001b[39m\u001b[32m/usr/local/python/3.12.1/lib/python3.12/site-packages/keras/src/utils/audio_dataset_utils.py:4\u001b[39m\n\u001b[32m      1\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mnumpy\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mnp\u001b[39;00m\n\u001b[32m      3\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mkeras\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01msrc\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mapi_export\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m keras_export\n\u001b[32m----> \u001b[39m\u001b[32m4\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mkeras\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01msrc\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mutils\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m dataset_utils\n\u001b[32m      5\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mkeras\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01msrc\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mutils\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mmodule_utils\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m tensorflow \u001b[38;5;28;01mas\u001b[39;00m tf\n\u001b[32m      6\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mkeras\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01msrc\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mutils\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mmodule_utils\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m tensorflow_io \u001b[38;5;28;01mas\u001b[39;00m tfio\n",
            "\u001b[36mFile \u001b[39m\u001b[32m/usr/local/python/3.12.1/lib/python3.12/site-packages/keras/src/utils/dataset_utils.py:9\u001b[39m\n\u001b[32m      5\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mmultiprocessing\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mpool\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m ThreadPool\n\u001b[32m      7\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mnumpy\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mnp\u001b[39;00m\n\u001b[32m----> \u001b[39m\u001b[32m9\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mkeras\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01msrc\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m tree\n\u001b[32m     10\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mkeras\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01msrc\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mapi_export\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m keras_export\n\u001b[32m     11\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mkeras\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01msrc\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mutils\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m io_utils\n",
            "\u001b[36mFile \u001b[39m\u001b[32m/usr/local/python/3.12.1/lib/python3.12/site-packages/keras/src/tree/__init__.py:1\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m1\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mkeras\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01msrc\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mtree\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mtree_api\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m assert_same_paths\n\u001b[32m      2\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mkeras\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01msrc\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mtree\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mtree_api\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m assert_same_structure\n\u001b[32m      3\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mkeras\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01msrc\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mtree\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mtree_api\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m flatten\n",
            "\u001b[36mFile \u001b[39m\u001b[32m/usr/local/python/3.12.1/lib/python3.12/site-packages/keras/src/tree/tree_api.py:8\u001b[39m\n\u001b[32m      5\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mkeras\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01msrc\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mutils\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mmodule_utils\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m optree\n\u001b[32m      7\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m optree.available:\n\u001b[32m----> \u001b[39m\u001b[32m8\u001b[39m     \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mkeras\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01msrc\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mtree\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m optree_impl \u001b[38;5;28;01mas\u001b[39;00m tree_impl\n\u001b[32m      9\u001b[39m \u001b[38;5;28;01melif\u001b[39;00m dmtree.available:\n\u001b[32m     10\u001b[39m     \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mkeras\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01msrc\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mtree\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m dmtree_impl \u001b[38;5;28;01mas\u001b[39;00m tree_impl\n",
            "\u001b[36mFile \u001b[39m\u001b[32m/usr/local/python/3.12.1/lib/python3.12/site-packages/keras/src/tree/optree_impl.py:13\u001b[39m\n\u001b[32m     11\u001b[39m \u001b[38;5;66;03m# Register backend-specific node classes\u001b[39;00m\n\u001b[32m     12\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m backend() == \u001b[33m\"\u001b[39m\u001b[33mtensorflow\u001b[39m\u001b[33m\"\u001b[39m:\n\u001b[32m---> \u001b[39m\u001b[32m13\u001b[39m     \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mtensorflow\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mpython\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mtrackable\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mdata_structures\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m ListWrapper\n\u001b[32m     14\u001b[39m     \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mtensorflow\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mpython\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mtrackable\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mdata_structures\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m _DictWrapper\n\u001b[32m     16\u001b[39m     optree.register_pytree_node(\n\u001b[32m     17\u001b[39m         ListWrapper,\n\u001b[32m     18\u001b[39m         \u001b[38;5;28;01mlambda\u001b[39;00m x: (x, \u001b[38;5;28;01mNone\u001b[39;00m),\n\u001b[32m     19\u001b[39m         \u001b[38;5;28;01mlambda\u001b[39;00m metadata, children: ListWrapper(\u001b[38;5;28mlist\u001b[39m(children)),\n\u001b[32m     20\u001b[39m         namespace=\u001b[33m\"\u001b[39m\u001b[33mkeras\u001b[39m\u001b[33m\"\u001b[39m,\n\u001b[32m     21\u001b[39m     )\n",
            "\u001b[36mFile \u001b[39m\u001b[32m/usr/local/python/3.12.1/lib/python3.12/site-packages/tensorflow/__init__.py:49\u001b[39m\n\u001b[32m     46\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mtensorflow\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mpython\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m tf2 \u001b[38;5;28;01mas\u001b[39;00m _tf2\n\u001b[32m     47\u001b[39m _tf2.enable()\n\u001b[32m---> \u001b[39m\u001b[32m49\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mtensorflow\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01m_api\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mv2\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m __internal__\n\u001b[32m     50\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mtensorflow\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01m_api\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mv2\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m __operators__\n\u001b[32m     51\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mtensorflow\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01m_api\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mv2\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m audio\n",
            "\u001b[36mFile \u001b[39m\u001b[32m/usr/local/python/3.12.1/lib/python3.12/site-packages/tensorflow/_api/v2/__internal__/__init__.py:8\u001b[39m\n\u001b[32m      3\u001b[39m \u001b[33;03m\"\"\"Public API for tf._api.v2.__internal__ namespace\u001b[39;00m\n\u001b[32m      4\u001b[39m \u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m      6\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01msys\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01m_sys\u001b[39;00m\n\u001b[32m----> \u001b[39m\u001b[32m8\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mtensorflow\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01m_api\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mv2\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01m__internal__\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m autograph\n\u001b[32m      9\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mtensorflow\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01m_api\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mv2\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01m__internal__\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m decorator\n\u001b[32m     10\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mtensorflow\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01m_api\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mv2\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01m__internal__\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m dispatch\n",
            "\u001b[36mFile \u001b[39m\u001b[32m/usr/local/python/3.12.1/lib/python3.12/site-packages/tensorflow/_api/v2/__internal__/autograph/__init__.py:8\u001b[39m\n\u001b[32m      3\u001b[39m \u001b[33;03m\"\"\"Public API for tf._api.v2.__internal__.autograph namespace\u001b[39;00m\n\u001b[32m      4\u001b[39m \u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m      6\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01msys\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01m_sys\u001b[39;00m\n\u001b[32m----> \u001b[39m\u001b[32m8\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mtensorflow\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mpython\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mautograph\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mcore\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mag_ctx\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m control_status_ctx \u001b[38;5;66;03m# line: 34\u001b[39;00m\n\u001b[32m      9\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mtensorflow\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mpython\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mautograph\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mimpl\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mapi\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m tf_convert \u001b[38;5;66;03m# line: 493\u001b[39;00m\n",
            "\u001b[36mFile \u001b[39m\u001b[32m/usr/local/python/3.12.1/lib/python3.12/site-packages/tensorflow/python/autograph/core/ag_ctx.py:21\u001b[39m\n\u001b[32m     18\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01minspect\u001b[39;00m\n\u001b[32m     19\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mthreading\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m21\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mtensorflow\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mpython\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mautograph\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mutils\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m ag_logging\n\u001b[32m     22\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mtensorflow\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mpython\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mutil\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mtf_export\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m tf_export\n\u001b[32m     25\u001b[39m stacks = threading.local()\n",
            "\u001b[36mFile \u001b[39m\u001b[32m/usr/local/python/3.12.1/lib/python3.12/site-packages/tensorflow/python/autograph/utils/__init__.py:17\u001b[39m\n\u001b[32m      1\u001b[39m \u001b[38;5;66;03m# Copyright 2016 The TensorFlow Authors. All Rights Reserved.\u001b[39;00m\n\u001b[32m      2\u001b[39m \u001b[38;5;66;03m#\u001b[39;00m\n\u001b[32m      3\u001b[39m \u001b[38;5;66;03m# Licensed under the Apache License, Version 2.0 (the \"License\");\u001b[39;00m\n\u001b[32m   (...)\u001b[39m\u001b[32m     13\u001b[39m \u001b[38;5;66;03m# limitations under the License.\u001b[39;00m\n\u001b[32m     14\u001b[39m \u001b[38;5;66;03m# ==============================================================================\u001b[39;00m\n\u001b[32m     15\u001b[39m \u001b[33;03m\"\"\"Utility module that contains APIs usable in the generated code.\"\"\"\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m17\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mtensorflow\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mpython\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mautograph\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mutils\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mcontext_managers\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m control_dependency_on_returns\n\u001b[32m     18\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mtensorflow\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mpython\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mautograph\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mutils\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mmisc\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m alias_tensors\n\u001b[32m     19\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mtensorflow\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mpython\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mautograph\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mutils\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mtensor_list\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m dynamic_list_append\n",
            "\u001b[36mFile \u001b[39m\u001b[32m/usr/local/python/3.12.1/lib/python3.12/site-packages/tensorflow/python/autograph/utils/context_managers.py:19\u001b[39m\n\u001b[32m     15\u001b[39m \u001b[33;03m\"\"\"Various context managers.\"\"\"\u001b[39;00m\n\u001b[32m     17\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mcontextlib\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m19\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mtensorflow\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mpython\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mframework\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m ops\n\u001b[32m     20\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mtensorflow\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mpython\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mops\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m tensor_array_ops\n\u001b[32m     23\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mcontrol_dependency_on_returns\u001b[39m(return_value):\n",
            "\u001b[36mFile \u001b[39m\u001b[32m/usr/local/python/3.12.1/lib/python3.12/site-packages/tensorflow/python/framework/ops.py:30\u001b[39m\n\u001b[32m     28\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mabsl\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m app\n\u001b[32m     29\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mnumpy\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mnp\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m30\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mnumpy\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m typing \u001b[38;5;28;01mas\u001b[39;00m npt\n\u001b[32m     32\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mgoogle\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mprotobuf\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m message\n\u001b[32m     33\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mtensorflow\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mcore\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mframework\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m attr_value_pb2\n",
            "\u001b[36mFile \u001b[39m\u001b[32m~/.local/lib/python3.12/site-packages/numpy/__init__.py:364\u001b[39m, in \u001b[36m__getattr__\u001b[39m\u001b[34m(attr)\u001b[39m\n",
            "\u001b[31mModuleNotFoundError\u001b[39m: No module named 'numpy.typing'"
          ]
        }
      ],
      "source": [
        "from keras.models import Sequential\n",
        "from keras.layers import Dense\n",
        "\n",
        "model = Sequential()\n",
        "\n",
        "model.add(Dense(128, input_shape=X_train[0].shape, activation='relu', name='dense_1'))\n",
        "model.add(Dense(64, activation='relu', name='dense_2'))\n",
        "model.add(Dense(1, activation='linear', name='dense_output'))\n",
        "\n",
        "model.compile(optimizer='adam', loss='mse', metrics=['mae'])\n",
        "model.summary()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Y7m71ooKs5of",
        "outputId": "3aea4e7a-8ae2-4c7a-d24c-b5ef44bb78d7"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/300\n",
            "11/11 [==============================] - 0s 13ms/step - loss: 3.1056 - mae: 1.2746 - val_loss: 6.4903 - val_mae: 2.3263\n",
            "Epoch 2/300\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 3.0890 - mae: 1.2914 - val_loss: 6.1012 - val_mae: 2.1863\n",
            "Epoch 3/300\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 3.0196 - mae: 1.2733 - val_loss: 5.8318 - val_mae: 2.1653\n",
            "Epoch 4/300\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 3.0628 - mae: 1.2515 - val_loss: 6.3057 - val_mae: 2.2313\n",
            "Epoch 5/300\n",
            "11/11 [==============================] - 0s 7ms/step - loss: 3.4225 - mae: 1.3339 - val_loss: 6.1970 - val_mae: 2.2517\n",
            "Epoch 6/300\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 3.1839 - mae: 1.2861 - val_loss: 6.9755 - val_mae: 2.3482\n",
            "Epoch 7/300\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 2.9615 - mae: 1.2478 - val_loss: 6.3080 - val_mae: 2.2863\n",
            "Epoch 8/300\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 2.9570 - mae: 1.2394 - val_loss: 5.8472 - val_mae: 2.1656\n",
            "Epoch 9/300\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 3.0805 - mae: 1.2740 - val_loss: 6.4946 - val_mae: 2.2335\n",
            "Epoch 10/300\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 2.9375 - mae: 1.2258 - val_loss: 6.5952 - val_mae: 2.3403\n",
            "Epoch 11/300\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 3.0368 - mae: 1.2654 - val_loss: 7.0089 - val_mae: 2.4176\n",
            "Epoch 12/300\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 2.9468 - mae: 1.2476 - val_loss: 7.3787 - val_mae: 2.4643\n",
            "Epoch 13/300\n",
            "11/11 [==============================] - 0s 7ms/step - loss: 3.2519 - mae: 1.3131 - val_loss: 6.1463 - val_mae: 2.2171\n",
            "Epoch 14/300\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 3.0011 - mae: 1.2697 - val_loss: 5.7391 - val_mae: 2.0867\n",
            "Epoch 15/300\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 3.1471 - mae: 1.2924 - val_loss: 5.2531 - val_mae: 1.8893\n",
            "Epoch 16/300\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 3.4437 - mae: 1.3759 - val_loss: 5.6807 - val_mae: 2.0771\n",
            "Epoch 17/300\n",
            "11/11 [==============================] - 0s 6ms/step - loss: 2.9948 - mae: 1.2832 - val_loss: 5.9346 - val_mae: 2.1430\n",
            "Epoch 18/300\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 3.0561 - mae: 1.2910 - val_loss: 5.5719 - val_mae: 2.0070\n",
            "Epoch 19/300\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 3.1802 - mae: 1.3139 - val_loss: 5.8655 - val_mae: 2.0065\n",
            "Epoch 20/300\n",
            "11/11 [==============================] - 0s 7ms/step - loss: 3.3241 - mae: 1.3643 - val_loss: 6.3614 - val_mae: 2.2864\n",
            "Epoch 21/300\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 3.1742 - mae: 1.2730 - val_loss: 6.8587 - val_mae: 2.3671\n",
            "Epoch 22/300\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 3.0009 - mae: 1.2669 - val_loss: 6.9494 - val_mae: 2.3801\n",
            "Epoch 23/300\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 2.9110 - mae: 1.2613 - val_loss: 7.2262 - val_mae: 2.4446\n",
            "Epoch 24/300\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 2.9996 - mae: 1.2739 - val_loss: 6.8526 - val_mae: 2.3765\n",
            "Epoch 25/300\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 2.9177 - mae: 1.2371 - val_loss: 6.7643 - val_mae: 2.3612\n",
            "Epoch 26/300\n",
            "11/11 [==============================] - 0s 6ms/step - loss: 2.9245 - mae: 1.2485 - val_loss: 7.4207 - val_mae: 2.4780\n",
            "Epoch 27/300\n",
            "11/11 [==============================] - 0s 6ms/step - loss: 2.8906 - mae: 1.2368 - val_loss: 6.5894 - val_mae: 2.3145\n",
            "Epoch 28/300\n",
            "11/11 [==============================] - 0s 9ms/step - loss: 3.1027 - mae: 1.3164 - val_loss: 6.7452 - val_mae: 2.3532\n",
            "Epoch 29/300\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 3.2392 - mae: 1.3037 - val_loss: 5.9846 - val_mae: 2.2175\n",
            "Epoch 30/300\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 3.1205 - mae: 1.3118 - val_loss: 5.4671 - val_mae: 1.9829\n",
            "Epoch 31/300\n",
            "11/11 [==============================] - 0s 7ms/step - loss: 3.1444 - mae: 1.2952 - val_loss: 6.4138 - val_mae: 2.2998\n",
            "Epoch 32/300\n",
            "11/11 [==============================] - 0s 8ms/step - loss: 2.8177 - mae: 1.2171 - val_loss: 6.1904 - val_mae: 2.2135\n",
            "Epoch 33/300\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 2.8099 - mae: 1.2288 - val_loss: 6.4477 - val_mae: 2.2905\n",
            "Epoch 34/300\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 2.8372 - mae: 1.2236 - val_loss: 6.0803 - val_mae: 2.2226\n",
            "Epoch 35/300\n",
            "11/11 [==============================] - 0s 7ms/step - loss: 2.8450 - mae: 1.2420 - val_loss: 6.8444 - val_mae: 2.3691\n",
            "Epoch 36/300\n",
            "11/11 [==============================] - 0s 6ms/step - loss: 2.8370 - mae: 1.2191 - val_loss: 7.1320 - val_mae: 2.4191\n",
            "Epoch 37/300\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 2.8052 - mae: 1.2143 - val_loss: 6.1429 - val_mae: 2.1765\n",
            "Epoch 38/300\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 2.8642 - mae: 1.2675 - val_loss: 5.6663 - val_mae: 2.1285\n",
            "Epoch 39/300\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 2.7523 - mae: 1.2113 - val_loss: 6.4998 - val_mae: 2.2922\n",
            "Epoch 40/300\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 2.7078 - mae: 1.1932 - val_loss: 6.5641 - val_mae: 2.3075\n",
            "Epoch 41/300\n",
            "11/11 [==============================] - 0s 6ms/step - loss: 2.8340 - mae: 1.2296 - val_loss: 5.4441 - val_mae: 1.9800\n",
            "Epoch 42/300\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 3.0942 - mae: 1.3181 - val_loss: 5.7155 - val_mae: 2.0400\n",
            "Epoch 43/300\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 3.0450 - mae: 1.2650 - val_loss: 6.3370 - val_mae: 2.2813\n",
            "Epoch 44/300\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 2.8525 - mae: 1.2263 - val_loss: 6.2141 - val_mae: 2.1570\n",
            "Epoch 45/300\n",
            "11/11 [==============================] - 0s 7ms/step - loss: 2.8161 - mae: 1.2339 - val_loss: 8.0029 - val_mae: 2.5507\n",
            "Epoch 46/300\n",
            "11/11 [==============================] - 0s 7ms/step - loss: 2.8777 - mae: 1.2605 - val_loss: 7.6761 - val_mae: 2.5145\n",
            "Epoch 47/300\n",
            "11/11 [==============================] - 0s 6ms/step - loss: 2.7128 - mae: 1.1990 - val_loss: 6.2182 - val_mae: 2.2031\n",
            "Epoch 48/300\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 2.7739 - mae: 1.2151 - val_loss: 6.0749 - val_mae: 2.1968\n",
            "Epoch 49/300\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 2.7153 - mae: 1.1860 - val_loss: 6.0647 - val_mae: 2.1610\n",
            "Epoch 50/300\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 2.7765 - mae: 1.2292 - val_loss: 6.5169 - val_mae: 2.2920\n",
            "Epoch 51/300\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 2.7030 - mae: 1.1986 - val_loss: 7.2107 - val_mae: 2.4419\n",
            "Epoch 52/300\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 2.6928 - mae: 1.1959 - val_loss: 6.2080 - val_mae: 2.2263\n",
            "Epoch 53/300\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 2.7066 - mae: 1.1938 - val_loss: 6.3904 - val_mae: 2.2800\n",
            "Epoch 54/300\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 2.7582 - mae: 1.2151 - val_loss: 7.0474 - val_mae: 2.3842\n",
            "Epoch 55/300\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 2.7897 - mae: 1.2172 - val_loss: 5.7064 - val_mae: 2.0756\n",
            "Epoch 56/300\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 2.7387 - mae: 1.2190 - val_loss: 5.6591 - val_mae: 2.1042\n",
            "Epoch 57/300\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 2.6661 - mae: 1.1739 - val_loss: 6.4114 - val_mae: 2.2629\n",
            "Epoch 58/300\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 2.7370 - mae: 1.2323 - val_loss: 6.5930 - val_mae: 2.3284\n",
            "Epoch 59/300\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 2.7472 - mae: 1.2126 - val_loss: 7.6551 - val_mae: 2.4849\n",
            "Epoch 60/300\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 2.7223 - mae: 1.1992 - val_loss: 6.4851 - val_mae: 2.2541\n",
            "Epoch 61/300\n",
            "11/11 [==============================] - 0s 6ms/step - loss: 2.6876 - mae: 1.2015 - val_loss: 5.8780 - val_mae: 2.1638\n",
            "Epoch 62/300\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 2.7657 - mae: 1.1943 - val_loss: 6.6599 - val_mae: 2.3208\n",
            "Epoch 63/300\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 2.6066 - mae: 1.1727 - val_loss: 7.0047 - val_mae: 2.3763\n",
            "Epoch 64/300\n",
            "11/11 [==============================] - 0s 6ms/step - loss: 2.6496 - mae: 1.1650 - val_loss: 5.8258 - val_mae: 2.0635\n",
            "Epoch 65/300\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 2.7141 - mae: 1.2322 - val_loss: 5.4886 - val_mae: 2.0479\n",
            "Epoch 66/300\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 2.6642 - mae: 1.1840 - val_loss: 6.2955 - val_mae: 2.2355\n",
            "Epoch 67/300\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 2.6472 - mae: 1.1869 - val_loss: 7.2390 - val_mae: 2.4332\n",
            "Epoch 68/300\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 2.6818 - mae: 1.2152 - val_loss: 7.0964 - val_mae: 2.4000\n",
            "Epoch 69/300\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 2.6161 - mae: 1.1772 - val_loss: 6.7383 - val_mae: 2.3436\n",
            "Epoch 70/300\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 2.6882 - mae: 1.2078 - val_loss: 7.5573 - val_mae: 2.5004\n",
            "Epoch 71/300\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 2.7844 - mae: 1.2299 - val_loss: 8.5783 - val_mae: 2.6415\n",
            "Epoch 72/300\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 2.7901 - mae: 1.2479 - val_loss: 7.3582 - val_mae: 2.4680\n",
            "Epoch 73/300\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 2.6358 - mae: 1.1827 - val_loss: 6.8671 - val_mae: 2.3739\n",
            "Epoch 74/300\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 2.7527 - mae: 1.2118 - val_loss: 8.2133 - val_mae: 2.5872\n",
            "Epoch 75/300\n",
            "11/11 [==============================] - 0s 7ms/step - loss: 2.9309 - mae: 1.2368 - val_loss: 7.8562 - val_mae: 2.5199\n",
            "Epoch 76/300\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 2.5919 - mae: 1.1828 - val_loss: 6.6293 - val_mae: 2.3199\n",
            "Epoch 77/300\n",
            "11/11 [==============================] - 0s 7ms/step - loss: 2.5963 - mae: 1.1730 - val_loss: 7.7850 - val_mae: 2.5249\n",
            "Epoch 78/300\n",
            "11/11 [==============================] - 0s 7ms/step - loss: 2.6084 - mae: 1.2001 - val_loss: 6.1792 - val_mae: 2.2263\n",
            "Epoch 79/300\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 2.5093 - mae: 1.1529 - val_loss: 5.9122 - val_mae: 2.1538\n",
            "Epoch 80/300\n",
            "11/11 [==============================] - 0s 6ms/step - loss: 2.5917 - mae: 1.1590 - val_loss: 5.7632 - val_mae: 2.0758\n",
            "Epoch 81/300\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 2.6665 - mae: 1.2134 - val_loss: 5.5361 - val_mae: 2.0680\n",
            "Epoch 82/300\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 2.5833 - mae: 1.1611 - val_loss: 6.1869 - val_mae: 2.1890\n",
            "Epoch 83/300\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 2.5547 - mae: 1.1721 - val_loss: 6.9741 - val_mae: 2.3627\n",
            "Epoch 84/300\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 2.5132 - mae: 1.1752 - val_loss: 6.7616 - val_mae: 2.3573\n",
            "Epoch 85/300\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 2.6077 - mae: 1.1781 - val_loss: 7.0095 - val_mae: 2.3780\n",
            "Epoch 86/300\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 2.5957 - mae: 1.1922 - val_loss: 7.8574 - val_mae: 2.5177\n",
            "Epoch 87/300\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 2.6846 - mae: 1.2191 - val_loss: 6.9521 - val_mae: 2.3854\n",
            "Epoch 88/300\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 2.5219 - mae: 1.1503 - val_loss: 6.6566 - val_mae: 2.3345\n",
            "Epoch 89/300\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 2.6600 - mae: 1.2024 - val_loss: 6.6106 - val_mae: 2.3230\n",
            "Epoch 90/300\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 2.7108 - mae: 1.2004 - val_loss: 6.1778 - val_mae: 2.1536\n",
            "Epoch 91/300\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 2.6129 - mae: 1.1881 - val_loss: 5.6555 - val_mae: 2.1161\n",
            "Epoch 92/300\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 2.5655 - mae: 1.1607 - val_loss: 5.9759 - val_mae: 2.1401\n",
            "Epoch 93/300\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 2.5541 - mae: 1.1677 - val_loss: 6.0543 - val_mae: 2.1846\n",
            "Epoch 94/300\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 2.5630 - mae: 1.1653 - val_loss: 6.2960 - val_mae: 2.2284\n",
            "Epoch 95/300\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 2.4573 - mae: 1.1545 - val_loss: 6.8705 - val_mae: 2.3748\n",
            "Epoch 96/300\n",
            "11/11 [==============================] - 0s 7ms/step - loss: 2.4930 - mae: 1.1522 - val_loss: 7.1943 - val_mae: 2.4296\n",
            "Epoch 97/300\n",
            "11/11 [==============================] - 0s 6ms/step - loss: 2.4550 - mae: 1.1501 - val_loss: 6.7250 - val_mae: 2.3432\n",
            "Epoch 98/300\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 2.6007 - mae: 1.2089 - val_loss: 5.7796 - val_mae: 2.1116\n",
            "Epoch 99/300\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 2.5919 - mae: 1.1575 - val_loss: 5.7974 - val_mae: 2.0382\n",
            "Epoch 100/300\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 2.5848 - mae: 1.1802 - val_loss: 5.1330 - val_mae: 1.8581\n",
            "Epoch 101/300\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 2.6668 - mae: 1.1927 - val_loss: 5.7051 - val_mae: 2.0952\n",
            "Epoch 102/300\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 2.5008 - mae: 1.1837 - val_loss: 6.1120 - val_mae: 2.2025\n",
            "Epoch 103/300\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 2.4027 - mae: 1.1503 - val_loss: 6.6367 - val_mae: 2.3232\n",
            "Epoch 104/300\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 2.4079 - mae: 1.1240 - val_loss: 6.2111 - val_mae: 2.2132\n",
            "Epoch 105/300\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 2.3964 - mae: 1.1330 - val_loss: 6.4244 - val_mae: 2.2586\n",
            "Epoch 106/300\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 2.4099 - mae: 1.1168 - val_loss: 5.6990 - val_mae: 2.1011\n",
            "Epoch 107/300\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 2.6621 - mae: 1.2238 - val_loss: 5.5626 - val_mae: 2.0299\n",
            "Epoch 108/300\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 2.5632 - mae: 1.1621 - val_loss: 5.7833 - val_mae: 2.1174\n",
            "Epoch 109/300\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 2.4385 - mae: 1.1155 - val_loss: 5.7329 - val_mae: 2.0404\n",
            "Epoch 110/300\n",
            "11/11 [==============================] - 0s 7ms/step - loss: 2.3767 - mae: 1.1245 - val_loss: 6.0852 - val_mae: 2.1782\n",
            "Epoch 111/300\n",
            "11/11 [==============================] - 0s 7ms/step - loss: 2.4244 - mae: 1.1326 - val_loss: 5.5596 - val_mae: 2.0262\n",
            "Epoch 112/300\n",
            "11/11 [==============================] - 0s 7ms/step - loss: 2.7497 - mae: 1.2265 - val_loss: 5.6519 - val_mae: 2.0279\n",
            "Epoch 113/300\n",
            "11/11 [==============================] - 0s 6ms/step - loss: 2.5707 - mae: 1.1673 - val_loss: 5.9753 - val_mae: 2.1308\n",
            "Epoch 114/300\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 2.6320 - mae: 1.1814 - val_loss: 5.6328 - val_mae: 2.0544\n",
            "Epoch 115/300\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 2.4922 - mae: 1.1848 - val_loss: 6.7076 - val_mae: 2.3219\n",
            "Epoch 116/300\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 2.3521 - mae: 1.1135 - val_loss: 6.1589 - val_mae: 2.1926\n",
            "Epoch 117/300\n",
            "11/11 [==============================] - 0s 7ms/step - loss: 2.4731 - mae: 1.1483 - val_loss: 6.7821 - val_mae: 2.3554\n",
            "Epoch 118/300\n",
            "11/11 [==============================] - 0s 9ms/step - loss: 2.3240 - mae: 1.1190 - val_loss: 7.3727 - val_mae: 2.4423\n",
            "Epoch 119/300\n",
            "11/11 [==============================] - 0s 9ms/step - loss: 2.4723 - mae: 1.1554 - val_loss: 7.1060 - val_mae: 2.3966\n",
            "Epoch 120/300\n",
            "11/11 [==============================] - 0s 8ms/step - loss: 2.5127 - mae: 1.1484 - val_loss: 6.3237 - val_mae: 2.2485\n",
            "Epoch 121/300\n",
            "11/11 [==============================] - 0s 10ms/step - loss: 2.3587 - mae: 1.1076 - val_loss: 5.7971 - val_mae: 2.0863\n",
            "Epoch 122/300\n",
            "11/11 [==============================] - 0s 9ms/step - loss: 2.4617 - mae: 1.1487 - val_loss: 6.0938 - val_mae: 2.1738\n",
            "Epoch 123/300\n",
            "11/11 [==============================] - 0s 9ms/step - loss: 2.3733 - mae: 1.1059 - val_loss: 6.3431 - val_mae: 2.2627\n",
            "Epoch 124/300\n",
            "11/11 [==============================] - 0s 8ms/step - loss: 2.3631 - mae: 1.1260 - val_loss: 6.4888 - val_mae: 2.2884\n",
            "Epoch 125/300\n",
            "11/11 [==============================] - 0s 10ms/step - loss: 2.3127 - mae: 1.0895 - val_loss: 7.8077 - val_mae: 2.4958\n",
            "Epoch 126/300\n",
            "11/11 [==============================] - 0s 7ms/step - loss: 2.6067 - mae: 1.2029 - val_loss: 8.2998 - val_mae: 2.5629\n",
            "Epoch 127/300\n",
            "11/11 [==============================] - 0s 7ms/step - loss: 2.8612 - mae: 1.2512 - val_loss: 7.0210 - val_mae: 2.3950\n",
            "Epoch 128/300\n",
            "11/11 [==============================] - 0s 7ms/step - loss: 2.3393 - mae: 1.0990 - val_loss: 5.4917 - val_mae: 2.0155\n",
            "Epoch 129/300\n",
            "11/11 [==============================] - 0s 9ms/step - loss: 2.4642 - mae: 1.1682 - val_loss: 5.9443 - val_mae: 2.1565\n",
            "Epoch 130/300\n",
            "11/11 [==============================] - 0s 9ms/step - loss: 2.3760 - mae: 1.1173 - val_loss: 5.9573 - val_mae: 2.1594\n",
            "Epoch 131/300\n",
            "11/11 [==============================] - 0s 8ms/step - loss: 2.3106 - mae: 1.1069 - val_loss: 6.7204 - val_mae: 2.3167\n",
            "Epoch 132/300\n",
            "11/11 [==============================] - 0s 9ms/step - loss: 2.3167 - mae: 1.1154 - val_loss: 7.9637 - val_mae: 2.5219\n",
            "Epoch 133/300\n",
            "11/11 [==============================] - 0s 9ms/step - loss: 2.4609 - mae: 1.2059 - val_loss: 5.6440 - val_mae: 2.0361\n",
            "Epoch 134/300\n",
            "11/11 [==============================] - 0s 10ms/step - loss: 2.3008 - mae: 1.1045 - val_loss: 6.0164 - val_mae: 2.1685\n",
            "Epoch 135/300\n",
            "11/11 [==============================] - 0s 8ms/step - loss: 2.3708 - mae: 1.1305 - val_loss: 6.5138 - val_mae: 2.2598\n",
            "Epoch 136/300\n",
            "11/11 [==============================] - 0s 9ms/step - loss: 2.4608 - mae: 1.1703 - val_loss: 6.6766 - val_mae: 2.3147\n",
            "Epoch 137/300\n",
            "11/11 [==============================] - 0s 9ms/step - loss: 2.4603 - mae: 1.1516 - val_loss: 6.9333 - val_mae: 2.3698\n",
            "Epoch 138/300\n",
            "11/11 [==============================] - 0s 9ms/step - loss: 2.3975 - mae: 1.1543 - val_loss: 7.4719 - val_mae: 2.4487\n",
            "Epoch 139/300\n",
            "11/11 [==============================] - 0s 9ms/step - loss: 2.5001 - mae: 1.1645 - val_loss: 6.1076 - val_mae: 2.1744\n",
            "Epoch 140/300\n",
            "11/11 [==============================] - 0s 9ms/step - loss: 2.3291 - mae: 1.1267 - val_loss: 5.9407 - val_mae: 2.1526\n",
            "Epoch 141/300\n",
            "11/11 [==============================] - 0s 9ms/step - loss: 2.2880 - mae: 1.0894 - val_loss: 5.9766 - val_mae: 2.1525\n",
            "Epoch 142/300\n",
            "11/11 [==============================] - 0s 10ms/step - loss: 2.2625 - mae: 1.0847 - val_loss: 5.9881 - val_mae: 2.1593\n",
            "Epoch 143/300\n",
            "11/11 [==============================] - 0s 9ms/step - loss: 2.2006 - mae: 1.0788 - val_loss: 6.3303 - val_mae: 2.2373\n",
            "Epoch 144/300\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 2.1871 - mae: 1.0665 - val_loss: 6.0582 - val_mae: 2.1839\n",
            "Epoch 145/300\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 2.2008 - mae: 1.0746 - val_loss: 6.1331 - val_mae: 2.1885\n",
            "Epoch 146/300\n",
            "11/11 [==============================] - 0s 6ms/step - loss: 2.2786 - mae: 1.1104 - val_loss: 6.2060 - val_mae: 2.2078\n",
            "Epoch 147/300\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 2.3328 - mae: 1.1192 - val_loss: 5.9550 - val_mae: 2.1384\n",
            "Epoch 148/300\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 2.2181 - mae: 1.0713 - val_loss: 5.7968 - val_mae: 2.1150\n",
            "Epoch 149/300\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 2.2409 - mae: 1.0972 - val_loss: 5.9287 - val_mae: 2.1267\n",
            "Epoch 150/300\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 2.3337 - mae: 1.0962 - val_loss: 6.8946 - val_mae: 2.3684\n",
            "Epoch 151/300\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 2.2601 - mae: 1.0876 - val_loss: 6.0412 - val_mae: 2.1787\n",
            "Epoch 152/300\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 2.2489 - mae: 1.0934 - val_loss: 6.9576 - val_mae: 2.3606\n",
            "Epoch 153/300\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 2.4422 - mae: 1.1621 - val_loss: 7.5121 - val_mae: 2.4676\n",
            "Epoch 154/300\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 2.3661 - mae: 1.1148 - val_loss: 7.8075 - val_mae: 2.4879\n",
            "Epoch 155/300\n",
            "11/11 [==============================] - 0s 6ms/step - loss: 2.3945 - mae: 1.1183 - val_loss: 6.0800 - val_mae: 2.1979\n",
            "Epoch 156/300\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 2.1596 - mae: 1.0671 - val_loss: 6.7190 - val_mae: 2.3271\n",
            "Epoch 157/300\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 2.3356 - mae: 1.1086 - val_loss: 6.4814 - val_mae: 2.2747\n",
            "Epoch 158/300\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 2.5117 - mae: 1.1546 - val_loss: 6.5503 - val_mae: 2.3013\n",
            "Epoch 159/300\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 2.2641 - mae: 1.1072 - val_loss: 6.6623 - val_mae: 2.3204\n",
            "Epoch 160/300\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 2.2858 - mae: 1.0967 - val_loss: 7.6679 - val_mae: 2.4694\n",
            "Epoch 161/300\n",
            "11/11 [==============================] - 0s 7ms/step - loss: 2.4349 - mae: 1.1538 - val_loss: 6.6095 - val_mae: 2.2948\n",
            "Epoch 162/300\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 2.3499 - mae: 1.1236 - val_loss: 6.5052 - val_mae: 2.2746\n",
            "Epoch 163/300\n",
            "11/11 [==============================] - 0s 6ms/step - loss: 2.1896 - mae: 1.0756 - val_loss: 6.2110 - val_mae: 2.2096\n",
            "Epoch 164/300\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 2.2087 - mae: 1.0779 - val_loss: 5.6345 - val_mae: 2.0817\n",
            "Epoch 165/300\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 2.2205 - mae: 1.0816 - val_loss: 6.3185 - val_mae: 2.2283\n",
            "Epoch 166/300\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 2.1515 - mae: 1.0681 - val_loss: 5.6650 - val_mae: 2.0715\n",
            "Epoch 167/300\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 2.2414 - mae: 1.1227 - val_loss: 5.2791 - val_mae: 1.9287\n",
            "Epoch 168/300\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 2.1918 - mae: 1.0836 - val_loss: 5.7261 - val_mae: 2.0714\n",
            "Epoch 169/300\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 2.2334 - mae: 1.0887 - val_loss: 5.9375 - val_mae: 2.1392\n",
            "Epoch 170/300\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 2.2414 - mae: 1.0911 - val_loss: 6.0152 - val_mae: 2.1737\n",
            "Epoch 171/300\n",
            "11/11 [==============================] - 0s 7ms/step - loss: 2.1833 - mae: 1.0625 - val_loss: 5.8127 - val_mae: 2.1033\n",
            "Epoch 172/300\n",
            "11/11 [==============================] - 0s 6ms/step - loss: 2.4030 - mae: 1.1314 - val_loss: 5.9893 - val_mae: 2.1544\n",
            "Epoch 173/300\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 2.3840 - mae: 1.1178 - val_loss: 6.0741 - val_mae: 2.1891\n",
            "Epoch 174/300\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 2.1456 - mae: 1.0766 - val_loss: 5.5277 - val_mae: 2.0051\n",
            "Epoch 175/300\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 2.2041 - mae: 1.0880 - val_loss: 5.8504 - val_mae: 2.1088\n",
            "Epoch 176/300\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 2.3313 - mae: 1.1232 - val_loss: 6.0504 - val_mae: 2.1697\n",
            "Epoch 177/300\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 2.2019 - mae: 1.0674 - val_loss: 5.9017 - val_mae: 2.0774\n",
            "Epoch 178/300\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 2.1109 - mae: 1.0535 - val_loss: 6.6432 - val_mae: 2.2888\n",
            "Epoch 179/300\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 2.2542 - mae: 1.1222 - val_loss: 6.5085 - val_mae: 2.2642\n",
            "Epoch 180/300\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 2.2093 - mae: 1.0806 - val_loss: 6.3545 - val_mae: 2.2379\n",
            "Epoch 181/300\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 2.1547 - mae: 1.0743 - val_loss: 6.7625 - val_mae: 2.3205\n",
            "Epoch 182/300\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 2.2385 - mae: 1.0687 - val_loss: 5.7779 - val_mae: 2.1145\n",
            "Epoch 183/300\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 2.1949 - mae: 1.0833 - val_loss: 6.4675 - val_mae: 2.2553\n",
            "Epoch 184/300\n",
            "11/11 [==============================] - 0s 4ms/step - loss: 2.1218 - mae: 1.0661 - val_loss: 5.9501 - val_mae: 2.1265\n",
            "Epoch 185/300\n",
            "11/11 [==============================] - 0s 4ms/step - loss: 2.1849 - mae: 1.0517 - val_loss: 5.6609 - val_mae: 2.0782\n",
            "Epoch 186/300\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 2.2320 - mae: 1.1023 - val_loss: 6.7602 - val_mae: 2.3052\n",
            "Epoch 187/300\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 2.1846 - mae: 1.0730 - val_loss: 6.3883 - val_mae: 2.2177\n",
            "Epoch 188/300\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 2.1373 - mae: 1.0731 - val_loss: 5.5920 - val_mae: 2.0247\n",
            "Epoch 189/300\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 2.0788 - mae: 1.0348 - val_loss: 5.9390 - val_mae: 2.1045\n",
            "Epoch 190/300\n",
            "11/11 [==============================] - 0s 7ms/step - loss: 2.1363 - mae: 1.0747 - val_loss: 6.0164 - val_mae: 2.1486\n",
            "Epoch 191/300\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 2.0472 - mae: 1.0374 - val_loss: 6.1864 - val_mae: 2.1783\n",
            "Epoch 192/300\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 2.0539 - mae: 1.0372 - val_loss: 6.3886 - val_mae: 2.2187\n",
            "Epoch 193/300\n",
            "11/11 [==============================] - 0s 6ms/step - loss: 2.0404 - mae: 1.0436 - val_loss: 5.5344 - val_mae: 1.9796\n",
            "Epoch 194/300\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 2.1724 - mae: 1.0828 - val_loss: 5.2129 - val_mae: 1.8834\n",
            "Epoch 195/300\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 2.1838 - mae: 1.0863 - val_loss: 5.7369 - val_mae: 2.0881\n",
            "Epoch 196/300\n",
            "11/11 [==============================] - 0s 7ms/step - loss: 2.0887 - mae: 1.0503 - val_loss: 5.6347 - val_mae: 2.0075\n",
            "Epoch 197/300\n",
            "11/11 [==============================] - 0s 6ms/step - loss: 2.0453 - mae: 1.0400 - val_loss: 5.9219 - val_mae: 2.0980\n",
            "Epoch 198/300\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 2.0293 - mae: 1.0263 - val_loss: 5.6676 - val_mae: 2.0227\n",
            "Epoch 199/300\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 2.0969 - mae: 1.0454 - val_loss: 6.1320 - val_mae: 2.1645\n",
            "Epoch 200/300\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 2.1320 - mae: 1.0601 - val_loss: 6.5845 - val_mae: 2.2817\n",
            "Epoch 201/300\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 2.1010 - mae: 1.0543 - val_loss: 5.4878 - val_mae: 2.0027\n",
            "Epoch 202/300\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 2.1295 - mae: 1.0426 - val_loss: 5.8475 - val_mae: 2.0946\n",
            "Epoch 203/300\n",
            "11/11 [==============================] - 0s 7ms/step - loss: 2.0185 - mae: 1.0329 - val_loss: 5.2404 - val_mae: 1.8968\n",
            "Epoch 204/300\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 2.2730 - mae: 1.1078 - val_loss: 5.4690 - val_mae: 1.9983\n",
            "Epoch 205/300\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 2.0662 - mae: 1.0469 - val_loss: 5.5398 - val_mae: 1.9806\n",
            "Epoch 206/300\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 2.0955 - mae: 1.0574 - val_loss: 5.7833 - val_mae: 2.0969\n",
            "Epoch 207/300\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 2.0738 - mae: 1.0596 - val_loss: 5.4059 - val_mae: 1.9929\n",
            "Epoch 208/300\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 2.3236 - mae: 1.1034 - val_loss: 5.4992 - val_mae: 1.9331\n",
            "Epoch 209/300\n",
            "11/11 [==============================] - 0s 6ms/step - loss: 2.1223 - mae: 1.0821 - val_loss: 5.4147 - val_mae: 1.9972\n",
            "Epoch 210/300\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 2.1539 - mae: 1.0694 - val_loss: 5.2579 - val_mae: 1.9584\n",
            "Epoch 211/300\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 2.1291 - mae: 1.0782 - val_loss: 5.9378 - val_mae: 2.1324\n",
            "Epoch 212/300\n",
            "11/11 [==============================] - 0s 6ms/step - loss: 2.0049 - mae: 1.0279 - val_loss: 5.7491 - val_mae: 2.0618\n",
            "Epoch 213/300\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 2.0273 - mae: 1.0343 - val_loss: 5.2808 - val_mae: 1.9764\n",
            "Epoch 214/300\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 2.0660 - mae: 1.0538 - val_loss: 5.4240 - val_mae: 1.9220\n",
            "Epoch 215/300\n",
            "11/11 [==============================] - 0s 7ms/step - loss: 2.2905 - mae: 1.1257 - val_loss: 5.8052 - val_mae: 2.0951\n",
            "Epoch 216/300\n",
            "11/11 [==============================] - 0s 7ms/step - loss: 1.9866 - mae: 1.0051 - val_loss: 5.9299 - val_mae: 2.1255\n",
            "Epoch 217/300\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 2.0319 - mae: 1.0429 - val_loss: 6.3235 - val_mae: 2.2051\n",
            "Epoch 218/300\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 1.9841 - mae: 1.0332 - val_loss: 6.2414 - val_mae: 2.1969\n",
            "Epoch 219/300\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 1.9316 - mae: 0.9963 - val_loss: 6.4783 - val_mae: 2.2382\n",
            "Epoch 220/300\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 2.2017 - mae: 1.1089 - val_loss: 7.2737 - val_mae: 2.3746\n",
            "Epoch 221/300\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 2.4688 - mae: 1.1914 - val_loss: 5.4645 - val_mae: 1.9586\n",
            "Epoch 222/300\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 2.1802 - mae: 1.0849 - val_loss: 5.5157 - val_mae: 2.0276\n",
            "Epoch 223/300\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 1.9787 - mae: 1.0167 - val_loss: 5.7179 - val_mae: 2.0663\n",
            "Epoch 224/300\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 1.9416 - mae: 1.0064 - val_loss: 5.9605 - val_mae: 2.1121\n",
            "Epoch 225/300\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 1.9660 - mae: 1.0161 - val_loss: 6.3744 - val_mae: 2.2105\n",
            "Epoch 226/300\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 1.9966 - mae: 1.0218 - val_loss: 6.2888 - val_mae: 2.2007\n",
            "Epoch 227/300\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 1.9378 - mae: 1.0095 - val_loss: 5.9031 - val_mae: 2.1016\n",
            "Epoch 228/300\n",
            "11/11 [==============================] - 0s 6ms/step - loss: 1.9350 - mae: 1.0010 - val_loss: 6.7423 - val_mae: 2.3086\n",
            "Epoch 229/300\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 2.1267 - mae: 1.0818 - val_loss: 6.3335 - val_mae: 2.2093\n",
            "Epoch 230/300\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 1.9317 - mae: 1.0041 - val_loss: 5.5223 - val_mae: 1.9773\n",
            "Epoch 231/300\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 2.0287 - mae: 1.0272 - val_loss: 6.3010 - val_mae: 2.2148\n",
            "Epoch 232/300\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 2.0751 - mae: 1.0521 - val_loss: 6.1084 - val_mae: 2.1707\n",
            "Epoch 233/300\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 2.0392 - mae: 1.0290 - val_loss: 6.4114 - val_mae: 2.1964\n",
            "Epoch 234/300\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 1.9969 - mae: 1.0319 - val_loss: 6.1065 - val_mae: 2.1191\n",
            "Epoch 235/300\n",
            "11/11 [==============================] - 0s 7ms/step - loss: 1.9597 - mae: 1.0083 - val_loss: 6.1328 - val_mae: 2.1640\n",
            "Epoch 236/300\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 1.9138 - mae: 1.0289 - val_loss: 6.9479 - val_mae: 2.3152\n",
            "Epoch 237/300\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 2.0420 - mae: 1.0437 - val_loss: 6.0989 - val_mae: 2.1446\n",
            "Epoch 238/300\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 1.9514 - mae: 1.0228 - val_loss: 5.3250 - val_mae: 1.9275\n",
            "Epoch 239/300\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 2.0105 - mae: 1.0386 - val_loss: 5.3567 - val_mae: 1.9194\n",
            "Epoch 240/300\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 1.9303 - mae: 0.9990 - val_loss: 5.7566 - val_mae: 2.0744\n",
            "Epoch 241/300\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 2.0518 - mae: 1.0440 - val_loss: 5.9598 - val_mae: 2.1064\n",
            "Epoch 242/300\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 2.3680 - mae: 1.1753 - val_loss: 5.6048 - val_mae: 2.0301\n",
            "Epoch 243/300\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 2.2747 - mae: 1.1294 - val_loss: 5.7483 - val_mae: 2.0514\n",
            "Epoch 244/300\n",
            "11/11 [==============================] - 0s 6ms/step - loss: 2.1213 - mae: 1.0581 - val_loss: 5.1827 - val_mae: 1.8795\n",
            "Epoch 245/300\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 2.4791 - mae: 1.2282 - val_loss: 5.3811 - val_mae: 1.9618\n",
            "Epoch 246/300\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 2.4343 - mae: 1.1637 - val_loss: 5.3724 - val_mae: 1.8924\n",
            "Epoch 247/300\n",
            "11/11 [==============================] - 0s 7ms/step - loss: 2.4302 - mae: 1.1728 - val_loss: 5.4197 - val_mae: 1.9498\n",
            "Epoch 248/300\n",
            "11/11 [==============================] - 0s 6ms/step - loss: 1.9927 - mae: 1.0386 - val_loss: 6.0205 - val_mae: 2.1135\n",
            "Epoch 249/300\n",
            "11/11 [==============================] - 0s 7ms/step - loss: 1.8749 - mae: 0.9966 - val_loss: 6.2073 - val_mae: 2.1633\n",
            "Epoch 250/300\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 1.8703 - mae: 0.9858 - val_loss: 5.8402 - val_mae: 2.0735\n",
            "Epoch 251/300\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 1.8694 - mae: 0.9901 - val_loss: 5.7735 - val_mae: 2.0783\n",
            "Epoch 252/300\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 1.8652 - mae: 1.0002 - val_loss: 5.3878 - val_mae: 1.9617\n",
            "Epoch 253/300\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 1.8424 - mae: 0.9834 - val_loss: 5.8022 - val_mae: 2.0615\n",
            "Epoch 254/300\n",
            "11/11 [==============================] - 0s 7ms/step - loss: 1.8921 - mae: 1.0015 - val_loss: 5.7890 - val_mae: 2.0873\n",
            "Epoch 255/300\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 2.0560 - mae: 1.0505 - val_loss: 6.3691 - val_mae: 2.2292\n",
            "Epoch 256/300\n",
            "11/11 [==============================] - 0s 6ms/step - loss: 1.9405 - mae: 1.0273 - val_loss: 6.1396 - val_mae: 2.1389\n",
            "Epoch 257/300\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 1.9078 - mae: 0.9964 - val_loss: 6.1909 - val_mae: 2.1563\n",
            "Epoch 258/300\n",
            "11/11 [==============================] - 0s 6ms/step - loss: 1.8631 - mae: 0.9937 - val_loss: 5.5365 - val_mae: 2.0068\n",
            "Epoch 259/300\n",
            "11/11 [==============================] - 0s 7ms/step - loss: 1.9543 - mae: 1.0101 - val_loss: 6.7844 - val_mae: 2.2533\n",
            "Epoch 260/300\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 2.4626 - mae: 1.2167 - val_loss: 6.0976 - val_mae: 2.1669\n",
            "Epoch 261/300\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 2.2384 - mae: 1.1492 - val_loss: 6.1069 - val_mae: 2.1786\n",
            "Epoch 262/300\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 1.9056 - mae: 1.0195 - val_loss: 6.1102 - val_mae: 2.1440\n",
            "Epoch 263/300\n",
            "11/11 [==============================] - 0s 7ms/step - loss: 1.8630 - mae: 0.9980 - val_loss: 5.8949 - val_mae: 2.0151\n",
            "Epoch 264/300\n",
            "11/11 [==============================] - 0s 6ms/step - loss: 1.7968 - mae: 0.9794 - val_loss: 6.3249 - val_mae: 2.1934\n",
            "Epoch 265/300\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 1.8903 - mae: 0.9825 - val_loss: 5.7154 - val_mae: 2.0661\n",
            "Epoch 266/300\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 1.8167 - mae: 0.9703 - val_loss: 5.6601 - val_mae: 2.0180\n",
            "Epoch 267/300\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 1.8711 - mae: 0.9900 - val_loss: 5.0114 - val_mae: 1.8699\n",
            "Epoch 268/300\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 2.0192 - mae: 1.0491 - val_loss: 5.3013 - val_mae: 1.9723\n",
            "Epoch 269/300\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 1.8963 - mae: 1.0264 - val_loss: 5.8411 - val_mae: 2.0705\n",
            "Epoch 270/300\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 1.8538 - mae: 0.9912 - val_loss: 6.2050 - val_mae: 2.1733\n",
            "Epoch 271/300\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 1.9353 - mae: 1.0410 - val_loss: 6.5796 - val_mae: 2.2191\n",
            "Epoch 272/300\n",
            "11/11 [==============================] - 0s 6ms/step - loss: 2.0912 - mae: 1.0653 - val_loss: 7.2108 - val_mae: 2.3528\n",
            "Epoch 273/300\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 1.8993 - mae: 1.0328 - val_loss: 6.2316 - val_mae: 2.1512\n",
            "Epoch 274/300\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 1.9801 - mae: 1.0312 - val_loss: 5.4856 - val_mae: 2.0009\n",
            "Epoch 275/300\n",
            "11/11 [==============================] - 0s 7ms/step - loss: 1.9120 - mae: 0.9957 - val_loss: 5.7472 - val_mae: 2.0582\n",
            "Epoch 276/300\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 1.7900 - mae: 0.9773 - val_loss: 6.0106 - val_mae: 2.1247\n",
            "Epoch 277/300\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 1.8773 - mae: 0.9817 - val_loss: 5.5723 - val_mae: 2.0179\n",
            "Epoch 278/300\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 1.8406 - mae: 1.0050 - val_loss: 7.3194 - val_mae: 2.3680\n",
            "Epoch 279/300\n",
            "11/11 [==============================] - 0s 7ms/step - loss: 2.0116 - mae: 1.0416 - val_loss: 6.3747 - val_mae: 2.2228\n",
            "Epoch 280/300\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 1.8286 - mae: 0.9801 - val_loss: 5.2984 - val_mae: 1.9519\n",
            "Epoch 281/300\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 1.7998 - mae: 0.9732 - val_loss: 5.6901 - val_mae: 2.0411\n",
            "Epoch 282/300\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 2.0855 - mae: 1.0653 - val_loss: 5.0633 - val_mae: 1.8825\n",
            "Epoch 283/300\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 1.9785 - mae: 1.0380 - val_loss: 5.4104 - val_mae: 1.9733\n",
            "Epoch 284/300\n",
            "11/11 [==============================] - 0s 6ms/step - loss: 1.9402 - mae: 0.9877 - val_loss: 5.0379 - val_mae: 1.8548\n",
            "Epoch 285/300\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 2.0268 - mae: 1.0588 - val_loss: 4.8808 - val_mae: 1.8593\n",
            "Epoch 286/300\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 1.9116 - mae: 0.9979 - val_loss: 5.1300 - val_mae: 1.9027\n",
            "Epoch 287/300\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 1.8042 - mae: 0.9600 - val_loss: 5.1929 - val_mae: 1.9436\n",
            "Epoch 288/300\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 1.8135 - mae: 0.9872 - val_loss: 5.7984 - val_mae: 2.0542\n",
            "Epoch 289/300\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 1.7921 - mae: 0.9663 - val_loss: 5.1156 - val_mae: 1.9278\n",
            "Epoch 290/300\n",
            "11/11 [==============================] - 0s 6ms/step - loss: 1.7762 - mae: 0.9776 - val_loss: 5.4598 - val_mae: 2.0021\n",
            "Epoch 291/300\n",
            "11/11 [==============================] - 0s 7ms/step - loss: 1.7719 - mae: 0.9642 - val_loss: 5.5716 - val_mae: 2.0326\n",
            "Epoch 292/300\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 1.8351 - mae: 0.9881 - val_loss: 6.2790 - val_mae: 2.1990\n",
            "Epoch 293/300\n",
            "11/11 [==============================] - 0s 6ms/step - loss: 1.8293 - mae: 0.9805 - val_loss: 5.5982 - val_mae: 2.0339\n",
            "Epoch 294/300\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 1.8143 - mae: 0.9849 - val_loss: 5.5947 - val_mae: 2.0159\n",
            "Epoch 295/300\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 2.0346 - mae: 1.0699 - val_loss: 5.6400 - val_mae: 2.0489\n",
            "Epoch 296/300\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 1.9648 - mae: 1.0571 - val_loss: 5.7493 - val_mae: 2.0950\n",
            "Epoch 297/300\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 1.8303 - mae: 0.9917 - val_loss: 5.8409 - val_mae: 2.1181\n",
            "Epoch 298/300\n",
            "11/11 [==============================] - 0s 7ms/step - loss: 1.9146 - mae: 1.0266 - val_loss: 6.4180 - val_mae: 2.2127\n",
            "Epoch 299/300\n",
            "11/11 [==============================] - 0s 9ms/step - loss: 1.8687 - mae: 1.0256 - val_loss: 7.0085 - val_mae: 2.3128\n",
            "Epoch 300/300\n",
            "11/11 [==============================] - 0s 9ms/step - loss: 2.1396 - mae: 1.0751 - val_loss: 7.6205 - val_mae: 2.4132\n"
          ]
        }
      ],
      "source": [
        "history = model.fit(X_train, y_train, epochs=300, validation_split=0.05, verbose = 1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oVVKHGqR17P6",
        "outputId": "bf3496cb-1bcb-4481-cce4-0de93b425390"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "5/5 [==============================] - 0s 3ms/step - loss: 16.5279 - mae: 3.0727\n",
            "Mean squared error on test data:  16.527891159057617\n",
            "Mean absolute error on test data:  3.0726842880249023\n"
          ]
        }
      ],
      "source": [
        "mse_nn, mae_nn = model.evaluate(X_test, y_test)\n",
        "\n",
        "print('Mean squared error on test data: ', mse_nn)\n",
        "print('Mean absolute error on test data: ', mae_nn)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XnOd4Mouu5-n",
        "outputId": "15e2d5bb-63dc-4ccc-db36-ccc6647c8828"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "5/5 [==============================] - 0s 4ms/step\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "array([17.782303], dtype=float32)"
            ]
          },
          "execution_count": 8,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Make predictions\n",
        "y_pred = model.predict(X_test)\n",
        "\n",
        "# View the first prediction\n",
        "y_pred[0]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GHqFSR7u0wYN"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.1"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
